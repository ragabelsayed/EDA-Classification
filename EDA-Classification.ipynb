{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Data Preparation and Splitting**  \n",
    "First, let's load the combined dataset and split it into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset \n",
    "data_files = ['stories_art-et-culture.csv', 'stories_economie.csv', 'stories_politique.csv', 'stories_regions.csv', 'stories_societe.csv', 'stories_sport.csv']\n",
    "df = pd.concat((pd.read_csv(filename) for filename in data_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target labels (y)\n",
    "X = df['story']\n",
    "y = df['topic']\n",
    "\n",
    "# Split the data into training (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Text Preprocessing**  \n",
    "Before training the classifier, we need to preprocess the text data by converting it into numerical representations. We'll use techniques like TF-IDF vectorization to transform the text into numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the vectorizer on the training set\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test set using the same vectorizer\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Train the Classifier**  \n",
    "We'll use a popular classifier such as the Multinomial Naive Bayes classifier for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Evaluate the Classifier**  \n",
    "Now, let's evaluate the classifier's performance on the test set and calculate precision, recall, F1-score, and accuracy for each class and the overall test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "art-et-culture       0.99      0.93      0.96       215\n",
      "      economie       0.86      0.89      0.88       222\n",
      "     politique       0.79      0.94      0.86       176\n",
      "       regions       0.88      0.66      0.75       204\n",
      "       societe       0.69      0.79      0.74       189\n",
      "         sport       0.99      0.97      0.98       194\n",
      "\n",
      "      accuracy                           0.86      1200\n",
      "     macro avg       0.87      0.86      0.86      1200\n",
      "  weighted avg       0.87      0.86      0.86      1200\n",
      "\n",
      "Accuracy: 0.8625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate classification metrics\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of Metrics:**\n",
    "- **Precision:** Precision is the ratio of true positive predictions to the total predicted positive instances. It measures the model's ability to avoid false positives. In the context of this task, precision indicates the percentage of correctly predicted articles for each class (topic).\n",
    "\n",
    "- **Recall:** Recall (also known as sensitivity) is the ratio of true positive predictions to the total actual positive instances. It measures the model's ability to find all positive instances. In this task, recall shows the percentage of correctly predicted articles out of all articles belonging to each class.\n",
    "\n",
    "- **F1-score:** The F1-score is the harmonic mean of precision and recall. It provides a balanced measure that considers both precision and recall. It is useful when there is an uneven class distribution.\n",
    "\n",
    "- **Accuracy:** Accuracy is the overall correct predictions out of all predictions. It provides an overall performance measure for the entire test set.\n",
    "\n",
    "**Enhancements for Better Results:**\n",
    "1. **Hyperparameter Tuning:** Experiment with different hyperparameters for the classifier, vectorizer, or other model components using techniques like GridSearchCV to find the optimal configuration.\n",
    "\n",
    "2. **Use Advanced Classifiers:** Try using more advanced classifiers like Support Vector Machines (SVM), Random Forest, or Gradient Boosting, as they may capture complex patterns in the text data better.\n",
    "\n",
    "3. **Feature Engineering:** Explore additional text preprocessing techniques like stemming, lemmatization, or using n-grams to create more informative features.\n",
    "\n",
    "4. **Handling Imbalanced Data:** If there's an imbalance in the number of examples per class, consider using techniques like oversampling, undersampling, or using class weights to address the class imbalance issue.\n",
    "\n",
    "5. **Ensemble Methods:** Combine multiple classifiers using ensemble methods like Voting or Stacking to improve overall performance.\n",
    "\n",
    "6. **Domain-specific Features:** Consider incorporating domain-specific features (e.g., word embeddings or topic features) that can provide valuable information for the classifier.\n",
    "\n",
    "7. **Error Analysis:** Analyze the misclassified examples to identify patterns or common sources of errors, and make necessary adjustments to the model or data preprocessing.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
